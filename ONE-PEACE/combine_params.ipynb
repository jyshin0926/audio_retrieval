{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import RobertaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roberta_model = RobertaModel.from_pretrained(\"roberta-large\")\n",
    "onepeace_model = torch.load(\"/workspace/jaeyoung/onepeace_pretrained_chkpoint/retrieval_onepeace_roberta_l_ensemble40.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logit_scale', 'encoder_wrapper.text_adapter.cls_embedding', 'encoder_wrapper.text_adapter.rp_bucket', 'encoder_wrapper.text_adapter.embed_tokens.weight', 'encoder_wrapper.text_adapter.embed_positions.weight', 'encoder_wrapper.text_adapter.rel_pos_table_list.0.weight', 'encoder_wrapper.audio_adapter.cls_pos_embed', 'encoder_wrapper.audio_adapter.cls_embedding', 'encoder_wrapper.audio_adapter.mask_embedding', 'encoder_wrapper.audio_adapter.rp_bucket', 'encoder_wrapper.audio_adapter.embed_audios.0.conv_layers.0.0.weight', 'encoder_wrapper.audio_adapter.embed_audios.0.conv_layers.0.2.1.weight', 'encoder_wrapper.audio_adapter.embed_audios.0.conv_layers.0.2.1.bias', 'encoder_wrapper.audio_adapter.embed_audios.0.conv_layers.1.0.weight', 'encoder_wrapper.audio_adapter.embed_audios.0.conv_layers.1.2.1.weight', 'encoder_wrapper.audio_adapter.embed_audios.0.conv_layers.1.2.1.bias', 'encoder_wrapper.audio_adapter.embed_audios.0.conv_layers.2.0.weight', 'encoder_wrapper.audio_adapter.embed_audios.0.conv_layers.2.2.1.weight', 'encoder_wrapper.audio_adapter.embed_audios.0.conv_layers.2.2.1.bias', 'encoder_wrapper.audio_adapter.embed_audios.0.conv_layers.3.0.weight', 'encoder_wrapper.audio_adapter.embed_audios.0.conv_layers.3.2.1.weight', 'encoder_wrapper.audio_adapter.embed_audios.0.conv_layers.3.2.1.bias', 'encoder_wrapper.audio_adapter.embed_audios.0.conv_layers.4.0.weight', 'encoder_wrapper.audio_adapter.embed_audios.0.conv_layers.4.2.1.weight', 'encoder_wrapper.audio_adapter.embed_audios.0.conv_layers.4.2.1.bias', 'encoder_wrapper.audio_adapter.embed_audios.0.conv_layers.5.0.weight', 'encoder_wrapper.audio_adapter.embed_audios.0.conv_layers.5.2.1.weight', 'encoder_wrapper.audio_adapter.embed_audios.0.conv_layers.5.2.1.bias', 'encoder_wrapper.audio_adapter.embed_audios.0.conv_layers.6.0.weight', 'encoder_wrapper.audio_adapter.embed_audios.0.conv_layers.6.2.1.weight', 'encoder_wrapper.audio_adapter.embed_audios.0.conv_layers.6.2.1.bias', 'encoder_wrapper.audio_adapter.embed_audios.2.weight', 'encoder_wrapper.audio_adapter.embed_audios.2.bias', 'encoder_wrapper.audio_adapter.embed_audios.3.weight', 'encoder_wrapper.audio_adapter.embed_audios.3.bias', 'encoder_wrapper.audio_adapter.embed_positions.1.0.weight', 'encoder_wrapper.audio_adapter.embed_positions.1.0.bias', 'encoder_wrapper.audio_adapter.embed_positions.2.0.weight', 'encoder_wrapper.audio_adapter.embed_positions.2.0.bias', 'encoder_wrapper.audio_adapter.embed_positions.3.0.weight', 'encoder_wrapper.audio_adapter.embed_positions.3.0.bias', 'encoder_wrapper.audio_adapter.embed_positions.4.0.weight', 'encoder_wrapper.audio_adapter.embed_positions.4.0.bias', 'encoder_wrapper.audio_adapter.embed_positions.5.0.weight', 'encoder_wrapper.audio_adapter.embed_positions.5.0.bias', 'encoder_wrapper.audio_adapter.rel_pos_table_list.0.weight', 'encoder_wrapper.fusion_model.version', 'encoder_wrapper.fusion_model.layers.0.gamma_1', 'encoder_wrapper.fusion_model.layers.0.gamma_2', 'encoder_wrapper.fusion_model.layers.0.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.0.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.0.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.0.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.0.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.0.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.0.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.0.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.0.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.0.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.0.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.0.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.0.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.0.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.0.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.0.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.0.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.0.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.0.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.0.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.0.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.0.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.0.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.0.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.0.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.1.gamma_1', 'encoder_wrapper.fusion_model.layers.1.gamma_2', 'encoder_wrapper.fusion_model.layers.1.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.1.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.1.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.1.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.1.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.1.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.1.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.1.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.1.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.1.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.1.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.1.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.1.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.1.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.1.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.1.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.1.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.1.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.1.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.1.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.1.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.1.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.1.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.1.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.1.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.2.gamma_1', 'encoder_wrapper.fusion_model.layers.2.gamma_2', 'encoder_wrapper.fusion_model.layers.2.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.2.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.2.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.2.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.2.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.2.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.2.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.2.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.2.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.2.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.2.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.2.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.2.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.2.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.2.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.2.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.2.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.2.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.2.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.2.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.2.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.2.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.2.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.2.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.2.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.3.gamma_1', 'encoder_wrapper.fusion_model.layers.3.gamma_2', 'encoder_wrapper.fusion_model.layers.3.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.3.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.3.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.3.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.3.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.3.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.3.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.3.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.3.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.3.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.3.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.3.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.3.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.3.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.3.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.3.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.3.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.3.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.3.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.3.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.3.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.3.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.3.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.3.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.3.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.4.gamma_1', 'encoder_wrapper.fusion_model.layers.4.gamma_2', 'encoder_wrapper.fusion_model.layers.4.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.4.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.4.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.4.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.4.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.4.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.4.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.4.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.4.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.4.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.4.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.4.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.4.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.4.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.4.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.4.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.4.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.4.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.4.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.4.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.4.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.4.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.4.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.4.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.4.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.5.gamma_1', 'encoder_wrapper.fusion_model.layers.5.gamma_2', 'encoder_wrapper.fusion_model.layers.5.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.5.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.5.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.5.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.5.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.5.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.5.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.5.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.5.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.5.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.5.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.5.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.5.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.5.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.5.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.5.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.5.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.5.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.5.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.5.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.5.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.5.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.5.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.5.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.5.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.6.gamma_1', 'encoder_wrapper.fusion_model.layers.6.gamma_2', 'encoder_wrapper.fusion_model.layers.6.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.6.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.6.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.6.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.6.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.6.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.6.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.6.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.6.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.6.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.6.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.6.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.6.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.6.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.6.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.6.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.6.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.6.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.6.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.6.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.6.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.6.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.6.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.6.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.6.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.7.gamma_1', 'encoder_wrapper.fusion_model.layers.7.gamma_2', 'encoder_wrapper.fusion_model.layers.7.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.7.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.7.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.7.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.7.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.7.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.7.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.7.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.7.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.7.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.7.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.7.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.7.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.7.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.7.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.7.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.7.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.7.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.7.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.7.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.7.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.7.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.7.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.7.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.7.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.8.gamma_1', 'encoder_wrapper.fusion_model.layers.8.gamma_2', 'encoder_wrapper.fusion_model.layers.8.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.8.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.8.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.8.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.8.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.8.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.8.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.8.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.8.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.8.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.8.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.8.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.8.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.8.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.8.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.8.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.8.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.8.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.8.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.8.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.8.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.8.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.8.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.8.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.8.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.9.gamma_1', 'encoder_wrapper.fusion_model.layers.9.gamma_2', 'encoder_wrapper.fusion_model.layers.9.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.9.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.9.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.9.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.9.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.9.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.9.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.9.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.9.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.9.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.9.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.9.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.9.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.9.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.9.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.9.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.9.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.9.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.9.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.9.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.9.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.9.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.9.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.9.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.9.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.10.gamma_1', 'encoder_wrapper.fusion_model.layers.10.gamma_2', 'encoder_wrapper.fusion_model.layers.10.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.10.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.10.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.10.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.10.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.10.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.10.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.10.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.10.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.10.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.10.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.10.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.10.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.10.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.10.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.10.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.10.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.10.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.10.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.10.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.10.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.10.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.10.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.10.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.10.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.11.gamma_1', 'encoder_wrapper.fusion_model.layers.11.gamma_2', 'encoder_wrapper.fusion_model.layers.11.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.11.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.11.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.11.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.11.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.11.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.11.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.11.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.11.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.11.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.11.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.11.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.11.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.11.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.11.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.11.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.11.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.11.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.11.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.11.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.11.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.11.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.11.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.11.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.11.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.12.gamma_1', 'encoder_wrapper.fusion_model.layers.12.gamma_2', 'encoder_wrapper.fusion_model.layers.12.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.12.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.12.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.12.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.12.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.12.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.12.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.12.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.12.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.12.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.12.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.12.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.12.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.12.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.12.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.12.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.12.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.12.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.12.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.12.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.12.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.12.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.12.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.12.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.12.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.13.gamma_1', 'encoder_wrapper.fusion_model.layers.13.gamma_2', 'encoder_wrapper.fusion_model.layers.13.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.13.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.13.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.13.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.13.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.13.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.13.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.13.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.13.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.13.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.13.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.13.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.13.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.13.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.13.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.13.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.13.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.13.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.13.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.13.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.13.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.13.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.13.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.13.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.13.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.14.gamma_1', 'encoder_wrapper.fusion_model.layers.14.gamma_2', 'encoder_wrapper.fusion_model.layers.14.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.14.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.14.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.14.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.14.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.14.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.14.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.14.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.14.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.14.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.14.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.14.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.14.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.14.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.14.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.14.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.14.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.14.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.14.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.14.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.14.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.14.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.14.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.14.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.14.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.15.gamma_1', 'encoder_wrapper.fusion_model.layers.15.gamma_2', 'encoder_wrapper.fusion_model.layers.15.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.15.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.15.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.15.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.15.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.15.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.15.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.15.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.15.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.15.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.15.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.15.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.15.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.15.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.15.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.15.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.15.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.15.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.15.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.15.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.15.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.15.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.15.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.15.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.15.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.16.gamma_1', 'encoder_wrapper.fusion_model.layers.16.gamma_2', 'encoder_wrapper.fusion_model.layers.16.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.16.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.16.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.16.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.16.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.16.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.16.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.16.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.16.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.16.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.16.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.16.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.16.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.16.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.16.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.16.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.16.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.16.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.16.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.16.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.16.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.16.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.16.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.16.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.16.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.17.gamma_1', 'encoder_wrapper.fusion_model.layers.17.gamma_2', 'encoder_wrapper.fusion_model.layers.17.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.17.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.17.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.17.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.17.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.17.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.17.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.17.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.17.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.17.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.17.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.17.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.17.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.17.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.17.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.17.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.17.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.17.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.17.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.17.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.17.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.17.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.17.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.17.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.17.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.18.gamma_1', 'encoder_wrapper.fusion_model.layers.18.gamma_2', 'encoder_wrapper.fusion_model.layers.18.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.18.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.18.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.18.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.18.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.18.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.18.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.18.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.18.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.18.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.18.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.18.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.18.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.18.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.18.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.18.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.18.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.18.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.18.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.18.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.18.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.18.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.18.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.18.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.18.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.19.gamma_1', 'encoder_wrapper.fusion_model.layers.19.gamma_2', 'encoder_wrapper.fusion_model.layers.19.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.19.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.19.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.19.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.19.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.19.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.19.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.19.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.19.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.19.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.19.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.19.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.19.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.19.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.19.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.19.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.19.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.19.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.19.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.19.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.19.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.19.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.19.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.19.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.19.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.20.gamma_1', 'encoder_wrapper.fusion_model.layers.20.gamma_2', 'encoder_wrapper.fusion_model.layers.20.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.20.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.20.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.20.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.20.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.20.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.20.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.20.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.20.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.20.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.20.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.20.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.20.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.20.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.20.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.20.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.20.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.20.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.20.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.20.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.20.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.20.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.20.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.20.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.20.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.21.gamma_1', 'encoder_wrapper.fusion_model.layers.21.gamma_2', 'encoder_wrapper.fusion_model.layers.21.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.21.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.21.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.21.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.21.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.21.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.21.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.21.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.21.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.21.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.21.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.21.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.21.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.21.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.21.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.21.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.21.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.21.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.21.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.21.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.21.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.21.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.21.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.21.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.21.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.22.gamma_1', 'encoder_wrapper.fusion_model.layers.22.gamma_2', 'encoder_wrapper.fusion_model.layers.22.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.22.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.22.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.22.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.22.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.22.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.22.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.22.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.22.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.22.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.22.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.22.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.22.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.22.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.22.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.22.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.22.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.22.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.22.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.22.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.22.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.22.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.22.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.22.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.22.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.23.gamma_1', 'encoder_wrapper.fusion_model.layers.23.gamma_2', 'encoder_wrapper.fusion_model.layers.23.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.23.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.23.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.23.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.23.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.23.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.23.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.23.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.23.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.23.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.23.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.23.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.23.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.23.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.23.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.23.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.23.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.23.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.23.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.23.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.23.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.23.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.23.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.23.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.23.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.24.gamma_1', 'encoder_wrapper.fusion_model.layers.24.gamma_2', 'encoder_wrapper.fusion_model.layers.24.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.24.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.24.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.24.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.24.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.24.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.24.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.24.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.24.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.24.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.24.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.24.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.24.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.24.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.24.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.24.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.24.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.24.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.24.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.24.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.24.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.24.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.24.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.24.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.24.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.25.gamma_1', 'encoder_wrapper.fusion_model.layers.25.gamma_2', 'encoder_wrapper.fusion_model.layers.25.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.25.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.25.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.25.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.25.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.25.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.25.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.25.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.25.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.25.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.25.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.25.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.25.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.25.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.25.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.25.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.25.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.25.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.25.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.25.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.25.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.25.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.25.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.25.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.25.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.26.gamma_1', 'encoder_wrapper.fusion_model.layers.26.gamma_2', 'encoder_wrapper.fusion_model.layers.26.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.26.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.26.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.26.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.26.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.26.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.26.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.26.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.26.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.26.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.26.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.26.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.26.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.26.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.26.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.26.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.26.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.26.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.26.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.26.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.26.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.26.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.26.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.26.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.26.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.27.gamma_1', 'encoder_wrapper.fusion_model.layers.27.gamma_2', 'encoder_wrapper.fusion_model.layers.27.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.27.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.27.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.27.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.27.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.27.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.27.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.27.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.27.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.27.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.27.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.27.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.27.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.27.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.27.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.27.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.27.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.27.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.27.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.27.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.27.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.27.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.27.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.27.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.27.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.28.gamma_1', 'encoder_wrapper.fusion_model.layers.28.gamma_2', 'encoder_wrapper.fusion_model.layers.28.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.28.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.28.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.28.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.28.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.28.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.28.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.28.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.28.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.28.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.28.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.28.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.28.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.28.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.28.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.28.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.28.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.28.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.28.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.28.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.28.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.28.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.28.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.28.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.28.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.29.gamma_1', 'encoder_wrapper.fusion_model.layers.29.gamma_2', 'encoder_wrapper.fusion_model.layers.29.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.29.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.29.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.29.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.29.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.29.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.29.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.29.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.29.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.29.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.29.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.29.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.29.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.29.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.29.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.29.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.29.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.29.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.29.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.29.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.29.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.29.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.29.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.29.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.29.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.30.gamma_1', 'encoder_wrapper.fusion_model.layers.30.gamma_2', 'encoder_wrapper.fusion_model.layers.30.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.30.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.30.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.30.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.30.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.30.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.30.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.30.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.30.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.30.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.30.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.30.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.30.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.30.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.30.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.30.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.30.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.30.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.30.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.30.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.30.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.30.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.30.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.30.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.30.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.31.gamma_1', 'encoder_wrapper.fusion_model.layers.31.gamma_2', 'encoder_wrapper.fusion_model.layers.31.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.31.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.31.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.31.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.31.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.31.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.31.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.31.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.31.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.31.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.31.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.31.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.31.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.31.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.31.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.31.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.31.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.31.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.31.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.31.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.31.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.31.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.31.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.31.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.31.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.32.gamma_1', 'encoder_wrapper.fusion_model.layers.32.gamma_2', 'encoder_wrapper.fusion_model.layers.32.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.32.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.32.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.32.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.32.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.32.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.32.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.32.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.32.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.32.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.32.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.32.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.32.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.32.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.32.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.32.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.32.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.32.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.32.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.32.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.32.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.32.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.32.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.32.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.32.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.33.gamma_1', 'encoder_wrapper.fusion_model.layers.33.gamma_2', 'encoder_wrapper.fusion_model.layers.33.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.33.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.33.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.33.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.33.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.33.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.33.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.33.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.33.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.33.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.33.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.33.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.33.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.33.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.33.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.33.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.33.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.33.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.33.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.33.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.33.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.33.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.33.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.33.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.33.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.34.gamma_1', 'encoder_wrapper.fusion_model.layers.34.gamma_2', 'encoder_wrapper.fusion_model.layers.34.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.34.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.34.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.34.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.34.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.34.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.34.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.34.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.34.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.34.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.34.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.34.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.34.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.34.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.34.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.34.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.34.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.34.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.34.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.34.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.34.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.34.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.34.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.34.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.34.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.35.gamma_1', 'encoder_wrapper.fusion_model.layers.35.gamma_2', 'encoder_wrapper.fusion_model.layers.35.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.35.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.35.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.35.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.35.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.35.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.35.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.35.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.35.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.35.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.35.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.35.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.35.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.35.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.35.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.35.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.35.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.35.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.35.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.35.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.35.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.35.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.35.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.35.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.35.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.36.gamma_1', 'encoder_wrapper.fusion_model.layers.36.gamma_2', 'encoder_wrapper.fusion_model.layers.36.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.36.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.36.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.36.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.36.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.36.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.36.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.36.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.36.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.36.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.36.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.36.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.36.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.36.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.36.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.36.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.36.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.36.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.36.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.36.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.36.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.36.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.36.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.36.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.36.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.37.gamma_1', 'encoder_wrapper.fusion_model.layers.37.gamma_2', 'encoder_wrapper.fusion_model.layers.37.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.37.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.37.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.37.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.37.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.37.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.37.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.37.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.37.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.37.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.37.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.37.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.37.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.37.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.37.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.37.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.37.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.37.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.37.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.37.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.37.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.37.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.37.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.37.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.37.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.38.gamma_1', 'encoder_wrapper.fusion_model.layers.38.gamma_2', 'encoder_wrapper.fusion_model.layers.38.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.38.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.38.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.38.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.38.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.38.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.38.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.38.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.38.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.38.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.38.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.38.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.38.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.38.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.38.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.38.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.38.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.38.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.38.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.38.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.38.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.38.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.38.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.38.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.38.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.39.gamma_1', 'encoder_wrapper.fusion_model.layers.39.gamma_2', 'encoder_wrapper.fusion_model.layers.39.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.39.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.39.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.39.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.39.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.39.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.39.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.39.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.39.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.39.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.39.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.39.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.39.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.39.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.39.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.39.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.39.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.39.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.39.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.39.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.39.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.39.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.39.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.39.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.39.final_layer_norm.bias', 'encoder_wrapper.fusion_model.text_layer_norm.weight', 'encoder_wrapper.fusion_model.text_layer_norm.bias', 'encoder_wrapper.fusion_model.audio_layer_norm.weight', 'encoder_wrapper.fusion_model.audio_layer_norm.bias', 'text_proj.weight', 'text_proj.bias', 'audio_proj.weight', 'audio_proj.bias'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onepeace_model['model'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['encoder_wrapper.text_adapter.cls_embedding', 'encoder_wrapper.text_adapter.rp_bucket', 'encoder_wrapper.text_adapter.embed_tokens.weight', 'encoder_wrapper.text_adapter.embed_positions.weight', 'encoder_wrapper.text_adapter.rel_pos_table_list.0.weight', 'encoder_wrapper.fusion_model.layers.0.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.0.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.0.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.0.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.0.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.0.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.1.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.1.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.1.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.1.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.1.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.1.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.2.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.2.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.2.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.2.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.2.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.2.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.3.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.3.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.3.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.3.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.3.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.3.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.4.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.4.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.4.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.4.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.4.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.4.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.5.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.5.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.5.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.5.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.5.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.5.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.6.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.6.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.6.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.6.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.6.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.6.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.7.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.7.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.7.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.7.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.7.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.7.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.8.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.8.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.8.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.8.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.8.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.8.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.9.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.9.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.9.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.9.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.9.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.9.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.10.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.10.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.10.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.10.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.10.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.10.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.11.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.11.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.11.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.11.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.11.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.11.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.12.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.12.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.12.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.12.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.12.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.12.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.13.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.13.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.13.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.13.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.13.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.13.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.14.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.14.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.14.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.14.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.14.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.14.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.15.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.15.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.15.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.15.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.15.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.15.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.16.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.16.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.16.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.16.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.16.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.16.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.17.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.17.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.17.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.17.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.17.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.17.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.18.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.18.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.18.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.18.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.18.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.18.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.19.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.19.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.19.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.19.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.19.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.19.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.20.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.20.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.20.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.20.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.20.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.20.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.21.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.21.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.21.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.21.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.21.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.21.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.22.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.22.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.22.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.22.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.22.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.22.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.23.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.23.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.23.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.23.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.23.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.23.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.24.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.24.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.24.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.24.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.24.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.24.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.25.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.25.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.25.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.25.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.25.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.25.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.26.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.26.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.26.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.26.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.26.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.26.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.27.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.27.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.27.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.27.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.27.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.27.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.28.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.28.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.28.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.28.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.28.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.28.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.29.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.29.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.29.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.29.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.29.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.29.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.30.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.30.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.30.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.30.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.30.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.30.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.31.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.31.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.31.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.31.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.31.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.31.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.32.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.32.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.32.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.32.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.32.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.32.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.33.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.33.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.33.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.33.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.33.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.33.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.34.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.34.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.34.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.34.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.34.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.34.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.35.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.35.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.35.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.35.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.35.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.35.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.36.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.36.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.36.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.36.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.36.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.36.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.37.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.37.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.37.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.37.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.37.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.37.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.38.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.38.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.38.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.38.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.38.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.38.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.39.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.39.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.39.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.39.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.39.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.39.text_ffn.3.bias', 'encoder_wrapper.fusion_model.text_layer_norm.weight', 'encoder_wrapper.fusion_model.text_layer_norm.bias', 'text_proj.weight', 'text_proj.bias']\n"
     ]
    }
   ],
   "source": [
    "print([name for name in onepeace_model['model'].keys() if 'text' in name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['encoder_wrapper.fusion_model.version', 'encoder_wrapper.fusion_model.layers.0.gamma_1', 'encoder_wrapper.fusion_model.layers.0.gamma_2', 'encoder_wrapper.fusion_model.layers.0.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.0.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.0.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.0.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.0.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.0.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.0.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.0.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.0.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.0.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.0.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.0.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.0.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.0.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.0.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.0.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.0.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.0.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.0.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.0.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.0.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.0.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.0.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.0.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.0.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.1.gamma_1', 'encoder_wrapper.fusion_model.layers.1.gamma_2', 'encoder_wrapper.fusion_model.layers.1.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.1.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.1.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.1.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.1.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.1.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.1.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.1.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.1.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.1.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.1.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.1.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.1.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.1.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.1.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.1.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.1.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.1.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.1.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.1.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.1.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.1.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.1.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.1.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.1.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.2.gamma_1', 'encoder_wrapper.fusion_model.layers.2.gamma_2', 'encoder_wrapper.fusion_model.layers.2.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.2.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.2.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.2.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.2.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.2.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.2.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.2.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.2.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.2.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.2.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.2.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.2.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.2.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.2.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.2.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.2.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.2.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.2.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.2.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.2.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.2.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.2.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.2.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.2.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.3.gamma_1', 'encoder_wrapper.fusion_model.layers.3.gamma_2', 'encoder_wrapper.fusion_model.layers.3.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.3.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.3.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.3.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.3.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.3.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.3.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.3.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.3.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.3.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.3.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.3.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.3.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.3.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.3.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.3.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.3.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.3.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.3.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.3.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.3.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.3.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.3.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.3.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.3.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.4.gamma_1', 'encoder_wrapper.fusion_model.layers.4.gamma_2', 'encoder_wrapper.fusion_model.layers.4.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.4.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.4.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.4.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.4.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.4.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.4.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.4.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.4.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.4.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.4.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.4.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.4.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.4.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.4.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.4.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.4.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.4.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.4.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.4.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.4.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.4.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.4.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.4.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.4.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.5.gamma_1', 'encoder_wrapper.fusion_model.layers.5.gamma_2', 'encoder_wrapper.fusion_model.layers.5.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.5.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.5.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.5.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.5.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.5.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.5.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.5.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.5.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.5.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.5.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.5.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.5.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.5.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.5.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.5.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.5.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.5.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.5.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.5.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.5.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.5.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.5.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.5.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.5.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.6.gamma_1', 'encoder_wrapper.fusion_model.layers.6.gamma_2', 'encoder_wrapper.fusion_model.layers.6.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.6.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.6.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.6.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.6.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.6.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.6.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.6.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.6.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.6.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.6.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.6.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.6.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.6.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.6.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.6.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.6.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.6.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.6.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.6.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.6.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.6.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.6.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.6.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.6.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.7.gamma_1', 'encoder_wrapper.fusion_model.layers.7.gamma_2', 'encoder_wrapper.fusion_model.layers.7.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.7.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.7.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.7.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.7.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.7.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.7.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.7.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.7.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.7.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.7.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.7.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.7.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.7.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.7.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.7.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.7.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.7.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.7.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.7.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.7.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.7.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.7.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.7.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.7.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.8.gamma_1', 'encoder_wrapper.fusion_model.layers.8.gamma_2', 'encoder_wrapper.fusion_model.layers.8.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.8.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.8.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.8.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.8.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.8.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.8.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.8.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.8.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.8.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.8.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.8.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.8.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.8.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.8.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.8.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.8.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.8.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.8.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.8.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.8.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.8.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.8.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.8.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.8.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.9.gamma_1', 'encoder_wrapper.fusion_model.layers.9.gamma_2', 'encoder_wrapper.fusion_model.layers.9.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.9.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.9.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.9.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.9.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.9.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.9.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.9.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.9.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.9.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.9.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.9.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.9.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.9.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.9.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.9.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.9.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.9.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.9.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.9.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.9.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.9.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.9.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.9.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.9.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.10.gamma_1', 'encoder_wrapper.fusion_model.layers.10.gamma_2', 'encoder_wrapper.fusion_model.layers.10.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.10.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.10.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.10.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.10.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.10.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.10.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.10.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.10.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.10.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.10.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.10.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.10.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.10.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.10.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.10.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.10.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.10.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.10.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.10.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.10.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.10.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.10.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.10.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.10.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.11.gamma_1', 'encoder_wrapper.fusion_model.layers.11.gamma_2', 'encoder_wrapper.fusion_model.layers.11.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.11.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.11.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.11.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.11.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.11.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.11.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.11.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.11.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.11.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.11.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.11.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.11.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.11.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.11.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.11.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.11.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.11.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.11.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.11.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.11.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.11.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.11.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.11.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.11.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.12.gamma_1', 'encoder_wrapper.fusion_model.layers.12.gamma_2', 'encoder_wrapper.fusion_model.layers.12.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.12.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.12.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.12.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.12.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.12.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.12.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.12.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.12.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.12.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.12.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.12.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.12.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.12.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.12.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.12.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.12.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.12.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.12.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.12.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.12.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.12.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.12.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.12.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.12.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.13.gamma_1', 'encoder_wrapper.fusion_model.layers.13.gamma_2', 'encoder_wrapper.fusion_model.layers.13.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.13.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.13.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.13.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.13.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.13.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.13.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.13.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.13.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.13.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.13.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.13.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.13.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.13.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.13.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.13.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.13.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.13.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.13.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.13.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.13.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.13.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.13.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.13.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.13.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.14.gamma_1', 'encoder_wrapper.fusion_model.layers.14.gamma_2', 'encoder_wrapper.fusion_model.layers.14.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.14.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.14.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.14.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.14.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.14.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.14.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.14.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.14.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.14.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.14.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.14.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.14.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.14.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.14.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.14.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.14.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.14.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.14.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.14.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.14.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.14.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.14.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.14.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.14.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.15.gamma_1', 'encoder_wrapper.fusion_model.layers.15.gamma_2', 'encoder_wrapper.fusion_model.layers.15.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.15.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.15.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.15.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.15.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.15.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.15.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.15.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.15.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.15.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.15.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.15.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.15.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.15.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.15.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.15.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.15.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.15.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.15.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.15.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.15.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.15.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.15.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.15.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.15.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.16.gamma_1', 'encoder_wrapper.fusion_model.layers.16.gamma_2', 'encoder_wrapper.fusion_model.layers.16.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.16.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.16.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.16.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.16.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.16.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.16.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.16.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.16.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.16.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.16.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.16.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.16.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.16.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.16.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.16.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.16.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.16.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.16.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.16.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.16.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.16.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.16.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.16.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.16.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.17.gamma_1', 'encoder_wrapper.fusion_model.layers.17.gamma_2', 'encoder_wrapper.fusion_model.layers.17.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.17.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.17.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.17.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.17.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.17.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.17.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.17.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.17.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.17.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.17.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.17.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.17.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.17.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.17.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.17.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.17.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.17.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.17.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.17.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.17.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.17.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.17.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.17.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.17.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.18.gamma_1', 'encoder_wrapper.fusion_model.layers.18.gamma_2', 'encoder_wrapper.fusion_model.layers.18.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.18.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.18.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.18.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.18.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.18.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.18.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.18.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.18.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.18.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.18.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.18.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.18.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.18.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.18.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.18.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.18.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.18.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.18.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.18.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.18.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.18.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.18.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.18.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.18.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.19.gamma_1', 'encoder_wrapper.fusion_model.layers.19.gamma_2', 'encoder_wrapper.fusion_model.layers.19.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.19.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.19.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.19.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.19.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.19.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.19.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.19.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.19.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.19.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.19.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.19.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.19.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.19.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.19.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.19.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.19.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.19.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.19.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.19.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.19.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.19.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.19.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.19.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.19.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.20.gamma_1', 'encoder_wrapper.fusion_model.layers.20.gamma_2', 'encoder_wrapper.fusion_model.layers.20.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.20.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.20.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.20.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.20.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.20.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.20.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.20.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.20.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.20.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.20.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.20.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.20.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.20.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.20.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.20.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.20.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.20.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.20.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.20.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.20.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.20.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.20.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.20.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.20.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.21.gamma_1', 'encoder_wrapper.fusion_model.layers.21.gamma_2', 'encoder_wrapper.fusion_model.layers.21.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.21.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.21.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.21.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.21.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.21.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.21.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.21.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.21.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.21.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.21.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.21.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.21.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.21.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.21.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.21.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.21.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.21.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.21.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.21.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.21.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.21.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.21.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.21.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.21.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.22.gamma_1', 'encoder_wrapper.fusion_model.layers.22.gamma_2', 'encoder_wrapper.fusion_model.layers.22.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.22.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.22.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.22.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.22.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.22.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.22.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.22.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.22.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.22.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.22.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.22.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.22.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.22.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.22.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.22.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.22.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.22.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.22.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.22.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.22.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.22.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.22.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.22.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.22.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.23.gamma_1', 'encoder_wrapper.fusion_model.layers.23.gamma_2', 'encoder_wrapper.fusion_model.layers.23.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.23.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.23.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.23.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.23.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.23.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.23.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.23.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.23.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.23.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.23.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.23.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.23.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.23.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.23.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.23.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.23.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.23.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.23.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.23.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.23.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.23.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.23.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.23.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.23.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.24.gamma_1', 'encoder_wrapper.fusion_model.layers.24.gamma_2', 'encoder_wrapper.fusion_model.layers.24.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.24.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.24.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.24.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.24.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.24.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.24.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.24.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.24.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.24.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.24.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.24.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.24.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.24.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.24.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.24.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.24.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.24.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.24.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.24.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.24.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.24.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.24.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.24.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.24.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.25.gamma_1', 'encoder_wrapper.fusion_model.layers.25.gamma_2', 'encoder_wrapper.fusion_model.layers.25.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.25.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.25.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.25.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.25.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.25.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.25.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.25.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.25.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.25.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.25.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.25.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.25.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.25.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.25.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.25.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.25.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.25.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.25.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.25.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.25.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.25.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.25.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.25.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.25.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.26.gamma_1', 'encoder_wrapper.fusion_model.layers.26.gamma_2', 'encoder_wrapper.fusion_model.layers.26.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.26.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.26.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.26.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.26.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.26.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.26.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.26.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.26.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.26.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.26.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.26.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.26.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.26.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.26.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.26.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.26.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.26.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.26.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.26.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.26.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.26.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.26.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.26.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.26.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.27.gamma_1', 'encoder_wrapper.fusion_model.layers.27.gamma_2', 'encoder_wrapper.fusion_model.layers.27.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.27.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.27.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.27.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.27.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.27.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.27.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.27.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.27.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.27.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.27.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.27.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.27.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.27.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.27.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.27.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.27.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.27.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.27.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.27.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.27.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.27.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.27.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.27.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.27.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.28.gamma_1', 'encoder_wrapper.fusion_model.layers.28.gamma_2', 'encoder_wrapper.fusion_model.layers.28.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.28.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.28.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.28.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.28.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.28.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.28.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.28.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.28.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.28.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.28.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.28.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.28.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.28.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.28.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.28.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.28.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.28.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.28.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.28.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.28.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.28.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.28.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.28.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.28.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.29.gamma_1', 'encoder_wrapper.fusion_model.layers.29.gamma_2', 'encoder_wrapper.fusion_model.layers.29.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.29.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.29.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.29.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.29.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.29.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.29.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.29.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.29.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.29.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.29.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.29.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.29.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.29.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.29.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.29.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.29.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.29.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.29.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.29.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.29.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.29.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.29.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.29.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.29.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.30.gamma_1', 'encoder_wrapper.fusion_model.layers.30.gamma_2', 'encoder_wrapper.fusion_model.layers.30.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.30.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.30.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.30.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.30.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.30.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.30.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.30.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.30.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.30.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.30.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.30.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.30.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.30.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.30.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.30.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.30.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.30.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.30.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.30.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.30.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.30.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.30.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.30.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.30.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.31.gamma_1', 'encoder_wrapper.fusion_model.layers.31.gamma_2', 'encoder_wrapper.fusion_model.layers.31.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.31.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.31.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.31.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.31.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.31.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.31.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.31.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.31.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.31.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.31.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.31.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.31.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.31.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.31.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.31.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.31.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.31.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.31.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.31.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.31.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.31.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.31.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.31.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.31.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.32.gamma_1', 'encoder_wrapper.fusion_model.layers.32.gamma_2', 'encoder_wrapper.fusion_model.layers.32.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.32.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.32.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.32.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.32.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.32.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.32.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.32.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.32.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.32.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.32.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.32.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.32.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.32.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.32.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.32.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.32.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.32.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.32.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.32.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.32.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.32.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.32.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.32.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.32.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.33.gamma_1', 'encoder_wrapper.fusion_model.layers.33.gamma_2', 'encoder_wrapper.fusion_model.layers.33.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.33.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.33.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.33.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.33.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.33.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.33.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.33.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.33.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.33.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.33.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.33.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.33.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.33.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.33.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.33.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.33.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.33.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.33.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.33.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.33.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.33.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.33.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.33.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.33.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.34.gamma_1', 'encoder_wrapper.fusion_model.layers.34.gamma_2', 'encoder_wrapper.fusion_model.layers.34.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.34.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.34.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.34.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.34.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.34.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.34.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.34.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.34.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.34.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.34.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.34.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.34.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.34.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.34.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.34.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.34.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.34.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.34.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.34.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.34.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.34.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.34.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.34.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.34.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.35.gamma_1', 'encoder_wrapper.fusion_model.layers.35.gamma_2', 'encoder_wrapper.fusion_model.layers.35.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.35.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.35.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.35.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.35.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.35.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.35.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.35.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.35.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.35.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.35.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.35.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.35.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.35.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.35.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.35.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.35.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.35.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.35.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.35.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.35.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.35.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.35.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.35.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.35.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.36.gamma_1', 'encoder_wrapper.fusion_model.layers.36.gamma_2', 'encoder_wrapper.fusion_model.layers.36.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.36.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.36.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.36.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.36.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.36.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.36.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.36.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.36.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.36.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.36.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.36.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.36.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.36.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.36.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.36.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.36.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.36.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.36.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.36.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.36.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.36.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.36.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.36.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.36.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.37.gamma_1', 'encoder_wrapper.fusion_model.layers.37.gamma_2', 'encoder_wrapper.fusion_model.layers.37.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.37.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.37.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.37.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.37.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.37.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.37.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.37.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.37.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.37.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.37.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.37.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.37.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.37.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.37.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.37.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.37.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.37.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.37.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.37.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.37.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.37.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.37.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.37.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.37.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.38.gamma_1', 'encoder_wrapper.fusion_model.layers.38.gamma_2', 'encoder_wrapper.fusion_model.layers.38.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.38.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.38.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.38.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.38.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.38.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.38.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.38.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.38.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.38.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.38.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.38.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.38.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.38.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.38.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.38.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.38.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.38.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.38.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.38.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.38.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.38.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.38.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.38.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.38.final_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.39.gamma_1', 'encoder_wrapper.fusion_model.layers.39.gamma_2', 'encoder_wrapper.fusion_model.layers.39.self_attn.ln.weight', 'encoder_wrapper.fusion_model.layers.39.self_attn.ln.bias', 'encoder_wrapper.fusion_model.layers.39.self_attn.k_proj.weight', 'encoder_wrapper.fusion_model.layers.39.self_attn.v_proj.weight', 'encoder_wrapper.fusion_model.layers.39.self_attn.v_proj.bias', 'encoder_wrapper.fusion_model.layers.39.self_attn.q_proj.weight', 'encoder_wrapper.fusion_model.layers.39.self_attn.q_proj.bias', 'encoder_wrapper.fusion_model.layers.39.self_attn.out_proj.weight', 'encoder_wrapper.fusion_model.layers.39.self_attn.out_proj.bias', 'encoder_wrapper.fusion_model.layers.39.self_attn_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.39.self_attn_layer_norm.bias', 'encoder_wrapper.fusion_model.layers.39.text_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.39.text_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.39.text_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.39.text_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.39.text_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.39.text_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.39.audio_ffn.0.wi_0.weight', 'encoder_wrapper.fusion_model.layers.39.audio_ffn.0.wi_1.weight', 'encoder_wrapper.fusion_model.layers.39.audio_ffn.2.weight', 'encoder_wrapper.fusion_model.layers.39.audio_ffn.2.bias', 'encoder_wrapper.fusion_model.layers.39.audio_ffn.3.weight', 'encoder_wrapper.fusion_model.layers.39.audio_ffn.3.bias', 'encoder_wrapper.fusion_model.layers.39.final_layer_norm.weight', 'encoder_wrapper.fusion_model.layers.39.final_layer_norm.bias', 'encoder_wrapper.fusion_model.text_layer_norm.weight', 'encoder_wrapper.fusion_model.text_layer_norm.bias', 'encoder_wrapper.fusion_model.audio_layer_norm.weight', 'encoder_wrapper.fusion_model.audio_layer_norm.bias']\n"
     ]
    }
   ],
   "source": [
    "print([name for name in onepeace_model['model'].keys() if 'fusion' in name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = onepeace_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'named_parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Unfreeze the last few layers, adjust this logic according to your model architecture\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Note: You need to adjust the unfreezing logic based on your specific model architecture.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnamed_parameters\u001b[49m():\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# Split the name by '.' and filter out non-numeric parts for safe integer conversion\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'named_parameters'"
     ]
    }
   ],
   "source": [
    "# Unfreeze the last few layers, adjust this logic according to your model architecture\n",
    "# Note: You need to adjust the unfreezing logic based on your specific model architecture.\n",
    "for name, param in model.named_parameters():\n",
    "    # Split the name by '.' and filter out non-numeric parts for safe integer conversion\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
